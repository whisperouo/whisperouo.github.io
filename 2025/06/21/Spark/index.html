<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author"><title> · Hexo</title><meta name="description" content="Spark中间结果保存在内存，延迟小
task以线程方式，任务启动快
核心概念RDD弹性分布式数据集（只封装计算逻辑，不保存数据）

不可变

可分区

并行计算


spark最基本的数据抽象
这个抽象的数据模型，让使用者可以不必关心底层数据是分布式的只需关心如何把应用逻辑转化为一系列转换函数，进"><meta name="og:description" content="Spark中间结果保存在内存，延迟小
task以线程方式，任务启动快
核心概念RDD弹性分布式数据集（只封装计算逻辑，不保存数据）

不可变

可分区

并行计算


spark最基本的数据抽象
这个抽象的数据模型，让使用者可以不必关心底层数据是分布式的只需关心如何把应用逻辑转化为一系列转换函数，进"><meta name="twitter:site" content="Hexo"><meta name="twitter:title" content=""><meta name="twitter:card" content="summary"><meta name="keywords" content=""><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/bootstrap.min.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="/css/style.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><meta name="generator" content="Hexo 7.3.0"><link rel="stylesheet" href="/css/prism.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><div class="container" id="stage"><div class="row"><div class="col-sm-3 col-xs-12 side-container invisible" id="side-bar"><div class="vertical-text site-title"><h3 class="site-title-small" tabindex="-1"><a class="a-title" href="/">Typography</a></h3><h1 class="site-title-large" tabindex="-1"><a class="a-title" href="/">活版印字</a></h1><!--h6(onclick="triggerSiteNav()") Trigger--></div><br class="visible-lg visible-md visible-sm"><div class="site-title-links" id="site-nav"><ul><li><a href="/">Home</a></li><li><a href="/archives">Archive</a></li><li class="soc"><a href="http://example.com/atom.xml" target="_blank" rel="noopener noreferrer" aria-label="RSS"><i class="fa fa-rss">&nbsp;</i></a></li></ul><div class="visible-lg visible-md visible-sm site-nav-footer"><br class="site-nav-footer-br"><footer><p>&copy;&nbsp;2025&nbsp;<a target="_blank" href="http://example.com" rel="noopener noreferrer">John Doe</a></p><p>Theme&nbsp;<a target="_blank" href="https://github.com/SumiMakito/hexo-theme-typography" rel="noopener noreferrer">Typography</a>&nbsp;by&nbsp;<a target="_blank" href="https://www.keep.moe" rel="noopener noreferrer">Makito</a></p><p>Proudly published with&nbsp;<a target="_blank" href="https://hexo.io" rel="noopener noreferrer">Hexo</a></p></footer></div></div></div><div class="col-sm-9 col-xs-12 main-container invisible" id="main-container"><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post-container"><p class="post-title"><a></a></p><p class="post-meta"><span class="date meta-item">Posted at&nbsp;2025-06-21</span></p><p class="post-abstract"><h1 id="Spark"><a href="#Spark" class="headerlink" title="Spark"></a>Spark</h1><p>中间结果保存在内存，延迟小</p>
<p>task以线程方式，任务启动快</p>
<h1 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h1><h2 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a><span data-type="text" style="color: var(--b3-font-color6);">RDD</span></h2><p>弹性分布式数据集（只封装计算逻辑，不保存数据）</p>
<ul>
<li><p>不可变</p>
</li>
<li><p>可分区</p>
</li>
<li><p>并行计算</p>
</li>
</ul>
<p>spark最基本的数据抽象</p>
<p>这个抽象的数据模型，让使用者可以不必关心底层数据是分布式的<br>只需关心如何把应用逻辑转化为一系列转换函数，进而实现管道化，<br>从而避免了存储中间结果，大大降低数据复制、磁盘IO的开销</p>
<p>有很多分片（分布式），可以指定分片数</p>
<p>不存储数据，只是记录数据位置，转换关系（调用什么方法）</p>
<p>惰性执行原因：action时对RDD操作形成DAG进行stage的划分和并行优化</p>
<h3 id="宽窄依赖"><a href="#宽窄依赖" class="headerlink" title="宽窄依赖"></a>宽窄依赖</h3><p><span data-type="text" style="color: var(--b3-font-color6);">区别：<br>父RDD数据是否进入不同的子RDD</span></p>
<p>设计原因：<br>窄依赖分区可以并行，一个分区丢失重新计算对应分区即可<br>宽依赖（介于两个stage之间），需要等待上一个stage计算完才可以计算</p>
<p>‍</p>
<h3 id="RDD缓存"><a href="#RDD缓存" class="headerlink" title="RDD缓存"></a>RDD缓存</h3><ol>
<li>persist</li>
<li>cache（调用了persist）</li>
</ol>
<p><strong>存储级别</strong></p>
<p><img src="/assets/image-20250520195900-wk88k2k.png" alt="image"></p>
<h3 id="Checkpoint"><a href="#Checkpoint" class="headerlink" title="Checkpoint"></a>Checkpoint</h3><p>更可靠的数据持久化</p>
<p><span data-type="text" style="background-color: var(--b3-card-info-background); color: var(--b3-card-info-color);">开发经验：<br>对使用频繁且重要的数据，先持久化，再checkpoint</span></p>
<p>持久化和checkpoint的区别：<br>持久化保存在本地磁盘或内存，checkpoint保存在HDFS这类可靠的存储<br>持久化会在程序结束时被清除，或是手动调用unpersist清除缓存，checkpoint在程序结束后依然存在</p>
<p>‍</p>
<h3 id="累加器和广播变量"><a href="#累加器和广播变量" class="headerlink" title="累加器和广播变量"></a><span data-type="text" style="color: var(--b3-font-color8);">累加器和广播变量</span></h3><p>‍</p>
<h3 id="RDD转化为dataframe的流程"><a href="#RDD转化为dataframe的流程" class="headerlink" title="RDD转化为dataframe的流程"></a>RDD转化为dataframe的流程</h3><ol>
<li>定义Schema（表结构）</li>
<li>将RDD映射为Row对象（一行是什么）</li>
<li>转换为dataframe（使用createDataFrame方法）</li>
</ol>
<p>‍</p>
<h2 id="DAG"><a href="#DAG" class="headerlink" title="DAG"></a>DAG</h2><p>有向无环图，记录RDD执行流程</p>
<p>边界：<br>开始—sparkcontext创建的RDD<br>结束—触发action</p>
<p>一个job一个DAG</p>
<p><img src="/assets/image-20250520201148-wf7qxgb.png" alt="image" title="一个job包含的多个stage"></p>
<p><strong>构建流程</strong></p>
<ol>
<li><p>读取HDFS文件，创建RDD对象</p>
</li>
<li><p>DAGScheduler计算RDD之间的依赖关系</p>
</li>
<li><p>从后往前划分stage</p>
<ol>
<li>遇到宽依赖，断开</li>
<li>遇到窄依赖，加入stage</li>
</ol>
</li>
<li><p>依赖关系形成了DAG</p>
</li>
</ol>
<h2 id="DStream"><a href="#DStream" class="headerlink" title="DStream"></a>DStream</h2><p>一连串的batch，操作单元是每个batch里的RDD</p>
<h2 id="spark-submit"><a href="#spark-submit" class="headerlink" title="spark-submit"></a>spark-submit</h2><p>官方shell脚本<br>用于提交任务，为spark作业申请资源</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">bin/spark-submit</span><br><span class="line">-- master 指定运行模式</span><br><span class="line">-- num-executors <span class="number">50</span>-<span class="number">100</span></span><br><span class="line">-- executor-cores <span class="number">2</span>-<span class="number">4</span></span><br><span class="line">-- executor-memory <span class="number">4</span>-8G</span><br><span class="line">-- driver-cores </span><br><span class="line">-- driver-memory 通常不设置，或1G，使用collect算子时注意保证够大</span><br></pre></td></tr></table></figure>

<p>executor-cores不是指物理核心和线程，只是一个虚拟概念<br>就算只有300个物理核心，但分配的executor-core总数为400，操作系统会通过时间片轮转等调度算法模拟更多的核心执行，可能会性能下降</p>
<h2 id="application、job、stage、task"><a href="#application、job、stage、task" class="headerlink" title="application、job、stage、task"></a>application、job、stage、task</h2><p>初始化一个spark context就是生成一个application</p>
<p>由于shuffle存在，不同stage是不能并行计算的，因为stage的计算需要依赖前面stage的shuffle结果</p>
<p>stage是由一组完全独立的计算任务（task）组成，每个task运算逻辑相同，只不过每个task只会处理自己对应的partition</p>
<p>task</p>
<ul>
<li>被送到某个executor上的工作单元</li>
<li>每个task处理一个rdd分区的数据</li>
<li>如果每个excutor有2个cpu core、4个task的话，会是先执行2个再执行2个</li>
<li>一个线程</li>
</ul>
<h3 id="为什么划分stage"><a href="#为什么划分stage" class="headerlink" title="为什么划分stage"></a>为什么划分stage</h3><p>减少磁盘I&#x2F;O：比如map操作的输出可以直接作为filter操作的输入，无需将中间结果存储到磁盘</p>
<h2 id="广播变量"><a href="#广播变量" class="headerlink" title="广播变量"></a>广播变量</h2><p><strong>创建方式</strong></p>
<p>​<code>Broadcast&lt;&gt; 变量名 = sc.broadcast(需要传输的数据)</code>​</p>
<p><strong>作用</strong></p>
<p>map join</p>
<h2 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h2><p>算子外的代码在driver运行<br>算子内的代码在executor运行</p>
<p>算子内经常会用到算子外的数据，需要序列化后传递</p>
<p><strong>方案</strong></p>
<p>一、Java序列化<br>比较重（字节多）</p>
<p>二、kryo序列化</p>
<h2 id="端口号"><a href="#端口号" class="headerlink" title="端口号"></a>端口号</h2><p>当前任务运行情况：4040</p>
<p>历史服务器：18080</p>
<p>yarn任务运行情况：8088</p>
<p>job：4040</p>
<h1 id="代码的组织结构"><a href="#代码的组织结构" class="headerlink" title="代码的组织结构"></a>代码的组织结构</h1><p>入口：SparkSession</p>
<p>​<code>SparkSession.builder()</code>​</p>
<p>‍</p>
<h1 id="数据切分与任务划分"><a href="#数据切分与任务划分" class="headerlink" title="数据切分与任务划分"></a>数据切分与任务划分</h1><p>输入分片 — task —组成— RDD</p>
<p>‍</p>
<h1 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h1><p>spark1.6</p>
<ul>
<li>之前，静态</li>
<li>之后，统一</li>
</ul>
<p>可以使用<code>spark.memory.useLegacyMode</code>​参数启用</p>
<h2 id="一、静态内存管理机制"><a href="#一、静态内存管理机制" class="headerlink" title="一、静态内存管理机制"></a>一、静态内存管理机制</h2><p>spark的内存被分为两个区域</p>
<ul>
<li><p>存储内存（storage memory）</p>
<ul>
<li>存储计算中间数据、RDD数据</li>
</ul>
</li>
<li><p>执行内存（execution memory）</p>
<ul>
<li>存储shuffle数据</li>
</ul>
</li>
</ul>
<p>静态是指spark不会动态调整二者比例，而是让用户预先配置</p>
<h2 id="二、统一内存管理机制"><a href="#二、统一内存管理机制" class="headerlink" title="二、统一内存管理机制"></a>二、统一内存管理机制</h2><p>‍</p>
<h1 id="工作组件"><a href="#工作组件" class="headerlink" title="工作组件"></a>工作组件</h1><h2 id="driver"><a href="#driver" class="headerlink" title="driver"></a>driver</h2><p>驱动器节点</p>
<p>执行main方法<br>不参与计算</p>
<p>负责</p>
<ul>
<li>将用户程序（application）转化为作业（job）</li>
<li>在executor之间调度任务（task）</li>
<li>跟踪executor的执行情况</li>
<li>通过UI展示运行情况</li>
</ul>
<h2 id="executor"><a href="#executor" class="headerlink" title="executor"></a>executor</h2><p>参与具体计算</p>
<p>集群中工作节点（worker）的一个JVM进程</p>
<p>负责</p>
<ul>
<li>运行具体任务（task），将结果返回给driver</li>
<li>通过自身的块管理器（block manager）为RDD提供内存缓存，缓存在executor进程中</li>
</ul>
<p>executor是一个独立的jvm进程<br>使用多线程模型可以并发运行多个task，每个task为一个线程</p>
<h2 id="cluster-manager"><a href="#cluster-manager" class="headerlink" title="cluster manager"></a>cluster manager</h2><h2 id="blockmanager"><a href="#blockmanager" class="headerlink" title="blockmanager"></a>blockmanager</h2><p>管理内存和磁盘上的数据块<br>各个节点（executor）都有一个BlockManager实例</p>
<p>‍</p>
<h1 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h1><ol>
<li>spark-submit提交一个spark作业</li>
<li>启动一个driver进程，可能在本地，可能在集群上某个节点，这个要看具体的部署模式（deploy-mode），向集群管理器申请该作业需要的资源（executor进程）</li>
<li>在各个工作节点上，启动一定数量的executor进程</li>
<li>driver将作业代码拆分为多个stage，每个stage负责一部分代码，每个stage包含一批并行的有相同的计算逻辑的task，只是处理的数据不同而已，这些task被放到executor中执行，被executor中的cpu core计算</li>
<li>一个stage所有task执行完后，结果写入各个节点的本地磁盘文件，作为下一个stage的输入，串行执行</li>
</ol>
<p>spark在运行一个任务时，yarn会分配对应executor数量的container跑任务，实际是一个jvm进程<br>且以yarn-cluster模式运行时，会多分配一个container用来跑applicationMaster进程，用于调控spark任务，该进程内存大小以spark.driver.memory控制</p>
<p>‍</p>
<h1 id="Shuffle"><a href="#Shuffle" class="headerlink" title="Shuffle"></a>Shuffle</h1><p>一、Hash Shuffle</p>
<p>二、Sort Shuffle</p>
<p>‍</p>
<h1 id="spark调优"><a href="#spark调优" class="headerlink" title="spark调优"></a>spark调优</h1><h3 id="基础调优"><a href="#基础调优" class="headerlink" title="基础调优"></a>基础调优</h3><p>最简单<br>增加资源</p>
<h4 id="一、调节最优的资源配置（分配更多的资源）"><a href="#一、调节最优的资源配置（分配更多的资源）" class="headerlink" title="一、调节最优的资源配置（分配更多的资源）"></a>一、调节最优的资源配置（分配更多的资源）</h4><p>spark-submit用于给spark作业分配资源<br>sparkconf设置spark作业具体参数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">调节spark-submit这个shell脚本的参数</span><br><span class="line">- num-executors *executor的数量* 一般是50-100（80）</span><br><span class="line">- executor-cores *executor的cpu core数量* 一般是2-3（2）</span><br><span class="line">- executor-memory *每个executor的内存大小* 一般是6-10（6g）</span><br><span class="line">- driver-memory *driver的内存大小（影响不大）* 一般是1-5 （5g）</span><br></pre></td></tr></table></figure>

<p>举例：一次spark任务就要消耗160个cpu core、500g内存</p>
<p>增加num-executor、增加executor-cores &#x3D;</p>
<ul>
<li>增加并行处理的task个数<br>如原20个executor，每个2cpu core，就是40个task并行</li>
</ul>
<p>增加executor-memory &#x3D;<br>15. 减少磁盘I&#x2F;O<br>	- 需要对RDD进行cache时，大内存可以写入更多，也就不需要写入磁盘<br>	- shuffle的reduce端需要进行数据存放和聚合，大内存可以更少写入磁盘或不写入磁盘<br>16. 减少垃圾回收次数<br>	- task执行可能会创建很多对象，内存较小可能会导致JVM堆频繁存满、频繁垃圾回收</p>
<p><strong>对着调好的资源配置，进行接下来的调优</strong></p>
<h4 id="二、调节并行度"><a href="#二、调节并行度" class="headerlink" title="二、调节并行度"></a>二、调节并行度</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().set(<span class="string">&quot;&quot;</span>spark.<span class="keyword">default</span>.parallelism<span class="string">&quot;, &quot;</span><span class="number">500</span><span class="string">&quot;)</span></span><br></pre></td></tr></table></figure>

<p>调节并行度实际就是充分利用集群计算资源</p>
<p>并行度，也就是task数量</p>
<ul>
<li>最少：等于总cpu core数量</li>
<li>推荐：2～3倍总cpu core数量</li>
</ul>
<p>因为实际情况，有的task快，有的task慢，要是数量相等，还是会造成一些资源浪费<br>设置成倍数后，一个task运行完，另一个task能立刻补上来，尽量让cpu core不空闲</p>
<p><strong>大部分情况，资源和并行度到位了，spark作业就很快了，几分钟</strong></p>
<h4 id="三、RDD架构重构及RDD持久化"><a href="#三、RDD架构重构及RDD持久化" class="headerlink" title="三、RDD架构重构及RDD持久化"></a>三、RDD架构重构及RDD持久化</h4><p>RDD重复计算带来的问题：HDFS-RDD1-RDD2需要走两遍，从15分钟变30分钟</p>
<p>RDD架构重构：尽量复用RDD，差不多的，可以抽取为一个公共RDD，供反复使用</p>
<p>纯内存方式持久化公共RDD时，可以考虑序列化<br>将RDD的每个partition数据，序列化成一个大的字节数组，就一个对象，大大减少了内存task占用<br>缺点是需要反序列化<br>序列化纯内存后还是OOM内存溢出，那就考虑磁盘+内存的方式，再往上加可以将其序列化<br>内存资源极度充足时，可以使用持久化的双副本机制提高可靠性</p>
<h4 id="四、广播大的变量"><a href="#四、广播大的变量" class="headerlink" title="四、广播大的变量"></a>四、广播大的变量</h4><h4 id="五、改用Kyro序列化"><a href="#五、改用Kyro序列化" class="headerlink" title="五、改用Kyro序列化"></a>五、改用Kyro序列化</h4><h4 id="六、使用fastutil优化数据格式"><a href="#六、使用fastutil优化数据格式" class="headerlink" title="六、使用fastutil优化数据格式"></a>六、使用fastutil优化数据格式</h4><h4 id="七、调节数据本地化等待时长"><a href="#七、调节数据本地化等待时长" class="headerlink" title="七、调节数据本地化等待时长"></a>七、调节数据本地化等待时长</h4><h3 id="JVM调优"><a href="#JVM调优" class="headerlink" title="JVM调优"></a>JVM调优</h3><p>minor gc &#x2F; full gc都会导致[[JVM]]工作线程停止工作</p>
<h4 id="一、降低cache操作的内存占比"><a href="#一、降低cache操作的内存占比" class="headerlink" title="一、降低cache操作的内存占比"></a>一、降低cache操作的内存占比</h4><h4 id="二、调节-executor堆外内存、连接等待时长"><a href="#二、调节-executor堆外内存、连接等待时长" class="headerlink" title="二、调节 executor堆外内存、连接等待时长"></a>二、调节 executor堆外内存、连接等待时长</h4><h3 id="shuffle调优"><a href="#shuffle调优" class="headerlink" title="shuffle调优"></a>shuffle调优</h3><p>spark.sql.shuffle.<strong>partitions</strong><br>分区数<br>默认200<br>优化：<br>小数据集：减少，比如50<br>大数据集：增加，比如1000或更多，取决于数据量和集群规模</p>
<p>spark.shuffle.file.<strong>buffer</strong><br>缓冲区大小<br>默认32k<br>优化：<br>增大以减少磁盘I&#x2F;O，如64k</p>
<p>spark.shuffle.io.<strong>retryWait</strong><br>网络延迟等待时间<br>默认5s<br>优化：<br>在高负载或网络抖动时增加，以便有足够的恢复时间</p>
<h4 id="一、合并map端输出文件"><a href="#一、合并map端输出文件" class="headerlink" title="一、合并map端输出文件"></a>一、合并map端输出文件</h4><p>开启命令</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">new</span> <span class="title class_">SparkConf</span>().set(<span class="string">&quot;spark.shuffle.consolidateFiles&quot;</span>, <span class="string">&quot;true&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>对比<br>1000个task，分配给100个executor<br>每个executor有2个cpu core（每次并行处理2个task），需要处理10个task<br>每个task处理出2个文件<br>每次处理产生4个文件，处理5次，共产生20个文件（1个executor）<br>合并前</p>
<h4 id="二、调节map端内存缓冲大小、reduce端内存占比"><a href="#二、调节map端内存缓冲大小、reduce端内存占比" class="headerlink" title="二、调节map端内存缓冲大小、reduce端内存占比"></a>二、调节map端内存缓冲大小、reduce端内存占比</h4><p>map端处理的数据量比较大时，可能出现缓冲数据频繁spill溢写到磁盘文件中（磁盘I&#x2F;O）</p>
<p>默认缓冲大小32K，每个task处理640KB的数据，就会发生640&#x2F;32&#x3D;20次溢写</p>
<p>配置方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">val</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().set(<span class="string">&quot;spark.shuffle.file.buffer&quot;</span>, <span class="string">&quot;64&quot;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="三、HashShuffleManager、SortShuffleManager"><a href="#三、HashShuffleManager、SortShuffleManager" class="headerlink" title="三、HashShuffleManager、SortShuffleManager"></a>三、HashShuffleManager、SortShuffleManager</h4><h3 id="算子调优"><a href="#算子调优" class="headerlink" title="算子调优"></a>算子调优</h3><h4 id="一、使用MapPartitions提升Map操作类性能"><a href="#一、使用MapPartitions提升Map操作类性能" class="headerlink" title="一、使用MapPartitions提升Map操作类性能"></a>一、使用MapPartitions提升Map操作类性能</h4><p>由一个元素执行一次function改为一个分区执行一次function</p>
<p>优点：当需要把数据通过JDBC写入时，map需要每个元素创建一个数据库连接，而mapPartitions只需在一个分区中创建一个数据库连接</p>
<p>缺点：<br>map处理数据时内存不足，可以垃圾回收掉<br>mapPartitions无法回收内存，可能OOM（内存溢出）</p>
<p>适用情况：<br>数据量不是特别大（估算RDD数据量、每个partition数据量、分配给每个executor的内存量，资源允许，可以考虑代替）</p>
<h4 id="二、filter后使用coalesce减少分区数量"><a href="#二、filter后使用coalesce减少分区数量" class="headerlink" title="二、filter后使用coalesce减少分区数量"></a>二、filter后使用coalesce减少分区数量</h4><h4 id="三、使用foreachPartition优化写数据库性能"><a href="#三、使用foreachPartition优化写数据库性能" class="headerlink" title="三、使用foreachPartition优化写数据库性能"></a>三、使用foreachPartition优化写数据库性能</h4><p>同调优方案一</p>
<p>将foreach改为foreachPartition<br>一次处理一个分区<br>一个分区的数据只需创建一个数据库连接<br>只需向数据库发送一次sql语句和多组参数</p>
<p>可能造成OOM（某个分区数据量非常大）</p>
<h4 id="四、使用repartition解决spark-sql低并行度的性能问题"><a href="#四、使用repartition解决spark-sql低并行度的性能问题" class="headerlink" title="四、使用repartition解决spark sql低并行度的性能问题"></a>四、使用repartition解决spark sql低并行度的性能问题</h4><h4 id="五、使用reduceByKey的本地聚合特性优化性能"><a href="#五、使用reduceByKey的本地聚合特性优化性能" class="headerlink" title="五、使用reduceByKey的本地聚合特性优化性能"></a>五、使用reduceByKey的本地聚合特性优化性能</h4><h1 id="数据倾斜"><a href="#数据倾斜" class="headerlink" title="数据倾斜"></a>数据倾斜</h1><h3 id="本质"><a href="#本质" class="headerlink" title="本质"></a>本质</h3><p>数据分布不均匀<br>某些key对应的数据远高于其他key<br>一个key对应一个task任务，导致某些task任务非常重</p>
<h3 id="定位方法"><a href="#定位方法" class="headerlink" title="定位方法"></a>定位方法</h3><p>Spark Web UI查看当前运行到了第几个stage<br>看一下当前这个stage各个task分配的数据量，从而确定是否因task分配的数据不均匀导致了数据倾斜<br>根据stage划分原理，推算出来发生倾斜的stage对应代码中的哪一部分，这部分代码中肯定会有一个[[shuffle|shuffle]]类算子</p>
<h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><p>将session粒度的数据与用户信息数据join<br>这一步可能会出现数据倾斜，适合用map join替换掉reduce join，也就是将user信息作为广播变量广播出去，然后再利用userId2SessionInfo在调用mapToPair算子的时候取出[[广播变量]]的值进行聚合user信息</p>
<h3 id="可能触发数据倾斜的算子"><a href="#可能触发数据倾斜的算子" class="headerlink" title="可能触发数据倾斜的算子"></a>可能触发数据倾斜的算子</h3><ol start="17">
<li>ByKey类</li>
<li>join</li>
</ol>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><h4 id="一、Hive-ETL预处理"><a href="#一、Hive-ETL预处理" class="headerlink" title="一、Hive ETL预处理"></a>一、Hive ETL预处理</h4><p>适用场景<br>Hive表中的数据本身很不均匀，且业务场景需要频繁对Hive表执行分析操作</p>
<p>本质<br>将Spark作业的shuffle操作提前到了Hive ETL中</p>
<p>实现思路<br>在Hive ETL预先对数据按照key进行聚合，或者是预先和其他表进行join<br>在Spark作业中针对的数据源就是预处理后的Hive表<br>那么在Spark作业中也就不需要使用原先的shuffle类算子执行这类操作了</p>
<p>优缺点<br>简单、效果好<br>完全规避了数据倾斜，Spark作业性能大幅提升<br>治标不治本，Hive ETL中还是会发生数据倾斜</p>
<h4 id="二、过滤导致倾斜的key"><a href="#二、过滤导致倾斜的key" class="headerlink" title="二、过滤导致倾斜的key"></a>二、过滤导致倾斜的key</h4><p>适用场景<br>业务需求需要能接受某些数据舍弃掉<br>比如100万个key，只有两个key数据量达到了10万，其他key对应的都是几十，那就抛弃这两个key<br>实现思路<br>从Hive表查数据的时候，直接用where过滤</p>
<h4 id="三、提高shuffle操作的reduce并行度"><a href="#三、提高shuffle操作的reduce并行度" class="headerlink" title="三、提高shuffle操作的reduce并行度"></a>三、提高shuffle操作的reduce并行度</h4><p>方案一二不适合，就方案三</p>
<p>调用shuffle类算子时传入并行度参数（提高并行度）<br>shuffle时会创建指定数量的reduce task<br>每个reduce task分配到更少的数据</p>
<p>没有从根本上解决数据倾斜，只是尽量减轻shuffle reduce task的压力</p>
<p>实际经验<br>最理想<br>减轻后可忽略不计<br>不太理想<br>稍微快一点<br>以前某个task需要5小时，现在需要4小时<br>以前某个task直接oom，现在不会了，但也很慢，需要5小时</p>
<p>不太理想的话，就换后四种方案</p>
<h4 id="四、使用随机key实现双重聚合"><a href="#四、使用随机key实现双重聚合" class="headerlink" title="四、使用随机key实现双重聚合"></a>四、使用随机key实现双重聚合</h4><p>针对groupByKey、reduceByKey</p>
<p>某个task的value太多，比如（1,1）（1,2）（1,3）（1,4）<br>给key加上随机前缀（map），比如形成（1_1,1）（2_1,2）（1_1,3）（2_1,4）<br>此时一个大task就被拆开为多个小的task（逻辑上）<br>进行局部聚合<br>再使用map去掉key前缀<br>进行全局聚合</p>
<h4 id="五、将reduce-join转换为map-join"><a href="#五、将reduce-join转换为map-join" class="headerlink" title="五、将reduce join转换为map join"></a>五、将reduce join转换为map join</h4><p>针对join</p>
<h4 id="六、sample采样倾斜key进行两次join"><a href="#六、sample采样倾斜key进行两次join" class="headerlink" title="六、sample采样倾斜key进行两次join"></a>六、sample采样倾斜key进行两次join</h4><p>针对join</p>
<h4 id="七、使用随机数、扩容表进行join"><a href="#七、使用随机数、扩容表进行join" class="headerlink" title="七、使用随机数、扩容表进行join"></a>七、使用随机数、扩容表进行join</h4><p>针对join</p>
<h1 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h1><h2 id="yarn-cluster和yarn-client区别"><a href="#yarn-cluster和yarn-client区别" class="headerlink" title="yarn-cluster和yarn-client区别"></a>yarn-cluster和yarn-client区别</h2><p>yarn模式：spark客户端直接连接yarn</p>
<p><strong>driver运行节点有区别</strong></p>
<ul>
<li>cluster在yarn，用于生产</li>
<li>client在本地，用于本地测试，有网络激增问题，本地可以看到log，方便调试</li>
</ul>
<h2 id="函数和算子的区别✅"><a href="#函数和算子的区别✅" class="headerlink" title="函数和算子的区别✅"></a>函数和算子的区别✅</h2><p>函数&#x2F;方法：本地对象API</p>
<p>算子：分布式对象API</p>
<h2 id="对spark懒执行的理解"><a href="#对spark懒执行的理解" class="headerlink" title="对spark懒执行的理解"></a>对spark懒执行的理解</h2><p>如果每个转换算子都要执行，那会导致在没有执行算子的时候，中间结果不会被输出，就相当于是黑盒，可能导致计算资源的浪费（白算了）</p>
<p>比如在饭店点菜，只有付款了厨师才会开始做，要是不付款就做，做完了不要了，那就是浪费</p>
<h2 id="流批一体原理"><a href="#流批一体原理" class="headerlink" title="流批一体原理"></a>流批一体原理</h2><ol>
<li>相同的编程模型，实际都是对rdd进行操作</li>
<li>相同的api，用的算子几乎一样</li>
<li>对流的操作实际为微批操作，不过在2.3后有个structured streaming，实现和flink一样真正的流处理</li>
</ol>
<h2 id="面对mr的优势与劣势"><a href="#面对mr的优势与劣势" class="headerlink" title="面对mr的优势与劣势"></a>面对mr的优势与劣势</h2><p><strong>优势</strong></p>
<p>DAG计算模型（速度快的根本原因）</p>
<ul>
<li>将多个操作合并成一个阶段（stage），某些任务可以在一个物理节点的内存中完成，减少了大量的shuffle和数据落盘的次数</li>
<li>比如map或是filter，都是可以直接基于内存计算</li>
</ul>
<p>可以将反复用到的数据cache到内存中，减少数据加载耗时</p>
<p>支持实时流处理，为企业提供了统一的大数据流批处理平台</p>
<p><strong>劣势</strong></p>
<p>稳定性不如mapreduce</p>
<ul>
<li>大量数据被缓存在内存中，java回收垃圾缓慢的情况严重，导致spark性能不稳定</li>
<li>mapreduce就算运行慢，但是可以运行完<br>对技术要求高一点</li>
<li>因为基于内存计算，面对超大数据（一次操作10亿以上），没有调优的话，容易出问题，比如OOM内存溢出<br>spark不能完全替代mapreduce</li>
<li>实际生产中可能因为内存资源不够导致任务失败，使用mapreduce更好</li>
</ul>
<h2 id="实战问题"><a href="#实战问题" class="headerlink" title="实战问题"></a>实战问题</h2><p>对一天的数据统计每十分钟用户的一个活跃度（活跃量）（可能用到Spark的一些算子）</p>
<ol>
<li>按每十分钟的时间窗口对数据分组</li>
<li>计算每个时间窗口内的用户活跃量</li>
</ol>
</p></div><div class="share"><span>Share</span>&nbsp;<span class="soc"><a class="fa fa-bookmark" href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank"></a></span><span class="soc"><a class="fa fa-weibo" href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));"></a></span><span class="soc"><a class="fa fa-twitter" target="_blank" rel="noopener" href="http://twitter.com/home?status=http://example.com/2025/06/21/Spark/%20Hexo%20"></a></span></div><div class="pagination"><p class="clearfix"><span class="pre pagbuttons"><a role="navigation" href="/2025/06/21/flink%E5%8E%9F%E7%90%86/" title="flink原理"><i class="fa fa-angle-double-left"></i>&nbsp;Previous post: flink原理</a></span><span>&nbsp;</span><span class="next pagbuttons"><a role="navigation" href="/2025/06/20/hello-world/" title="Hello World xusu">Next post: Hello World xusu&nbsp;<i class="fa fa-angle-double-right"></i></a></span></p></div></div></div></div><div class="visible-xs site-bottom-footer"><footer><p>&copy;&nbsp;2025&nbsp;<a target="_blank" href="http://example.com" rel="noopener noreferrer">John Doe</a></p><p>Theme&nbsp;<a target="_blank" href="https://github.com/SumiMakito/hexo-theme-typography" rel="noopener noreferrer">Typography</a>&nbsp;by&nbsp;<a target="_blank" href="https://www.keep.moe" rel="noopener noreferrer">Makito</a></p><p>Proudly published with&nbsp;<a target="_blank" href="https://hexo.io" rel="noopener noreferrer">Hexo</a></p></footer></div></div></div></div><script src="/js/jquery-3.1.0.min.js"></script><script src="/js/bootstrap.min.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/google-analytics.js"></script><script src="/js/typography.js"></script></body></html>